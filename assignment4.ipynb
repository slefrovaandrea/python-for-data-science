{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Assignment 4: some database operations**\n",
    "- **you will learn:** using joins, aggregation, groupby in Pandas\n",
    "- **task:**  See section 4.2 below\n",
    "- **deadline:** 17.11.2025\n",
    "- [Pandas documentation](https://pandas.pydata.org/docs/index.html)\n",
    "- ðŸ“ **Reminder:** Sync your GitHub repository with the main course repository, update your project in PyCharm, and after completing the assignment, commit and push your changes back to GitHub."
   ],
   "id": "188b7e6145d42315"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.430383Z",
     "start_time": "2025-11-17T15:27:42.899633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from debugpy.common.timestamp import reset\n",
    "from pandas import Timestamp\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)"
   ],
   "id": "7b549a3fe4c7a06b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.3.3\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.467370Z",
     "start_time": "2025-11-17T15:27:43.437096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 1) Build synthetic datasets\n",
    "# -------------------------------\n",
    "# sensor readouts (long-format)\n",
    "np.random.seed(42)\n",
    "N_SENSORS = 6\n",
    "sensors = [f'S{i+1}' for i in range(N_SENSORS)]\n",
    "\n",
    "start = pd.Timestamp('2025-11-01 00:00')\n",
    "periods = 24 * 6 # six measurements per hour for 24 hours\n",
    "freq = '10min' # 10-minute frequency\n",
    "idx = pd.date_range(start=start, periods=periods, freq=freq)\n",
    "\n",
    "rows = []\n",
    "for sensor in sensors:\n",
    "    base_temp = 15 + 5 * np.random.rand() # baseline temp different per sensor\n",
    "    base_hum = 40 + 20 * np.random.rand()\n",
    "    noise_t = np.random.normal(0, 1.5, size=len(idx))\n",
    "    noise_h = np.random.normal(0, 5.0, size=len(idx))\n",
    "    # add a diurnal temperature variation\n",
    "    hours = (idx.hour + idx.minute/60.0)\n",
    "    diurnal = 6 * np.sin(2 * np.pi * (hours - 6) / 24)\n",
    "    \n",
    "    temps = base_temp + diurnal + noise_t\n",
    "    hums = np.clip(base_hum - 0.5 * diurnal + noise_h, 0, 100)\n",
    "    \n",
    "    for ts, t, h in zip(idx, temps, hums):\n",
    "        rows.append({'sensor_id': sensor, 'timestamp': ts, 'temperature': t, 'humidity': h})\n",
    "\n",
    "sensor_df = pd.DataFrame(rows)\n",
    "\n",
    "# add some missing values intentionally and some outliers\n",
    "sensor_df.loc[sensor_df.sample(frac=0.01, random_state=1).index, 'temperature'] = np.nan\n",
    "sensor_df.loc[sensor_df.sample(frac=0.005, random_state=2).index, 'humidity'] = np.nan\n",
    "# inject outliers\n",
    "outlier_idx = sensor_df.sample(frac=0.002, random_state=3).index\n",
    "sensor_df.loc[outlier_idx, 'temperature'] += np.random.choice([20, -15], size=len(outlier_idx))\n",
    "\n",
    "print('--- sensor_df (head) ---')\n",
    "print(sensor_df.head())\n",
    "\n",
    "# sensor metadata (wide)\n",
    "meta = pd.DataFrame({\n",
    "'sensor_id': sensors,\n",
    "'location': ['Room A', 'Room B', 'Room C', 'Room A', 'Room D', 'Room B'],\n",
    "'type': ['thermo-hygro', 'thermo-hygro', 'thermo', 'thermo-hygro', 'hygro', 'thermo']\n",
    "})\n",
    "\n",
    "# events table (sparse)\n",
    "events = pd.DataFrame([\n",
    "{'sensor_id': 'S1', 'timestamp': start + pd.Timedelta(hours=5), 'event': 'maintenance'},\n",
    "{'sensor_id': 'S3', 'timestamp': start + pd.Timedelta(hours=8, minutes=20), 'event': 'calibration'},\n",
    "{'sensor_id': 'S2', 'timestamp': start + pd.Timedelta(hours=18), 'event': 'spike_detected'}\n",
    "])"
   ],
   "id": "b94f5c7b981487c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sensor_df (head) ---\n",
      "  sensor_id           timestamp  temperature   humidity\n",
      "0        S1 2025-11-01 00:00:00    11.844233  55.829533\n",
      "1        S1 2025-11-01 00:10:00    13.162956  55.409148\n",
      "2        S1 2025-11-01 00:20:00    10.544302  64.612578\n",
      "3        S1 2025-11-01 00:30:00          NaN  63.473544\n",
      "4        S1 2025-11-01 00:40:00    13.332673  63.221174\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.484485Z",
     "start_time": "2025-11-17T15:27:43.473796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 2) MultiIndex: set index as (sensor_id, timestamp)\n",
    "# -------------------------------\n",
    "sensor_mi = sensor_df.set_index(['sensor_id', 'timestamp']).sort_index()\n",
    "print('\\n--- sensor_mi (index sample) ---')\n",
    "print(sensor_mi.head())\n",
    "\n",
    "# show selecting using MultiIndex\n",
    "print('\\nSelect all readings for S2 between two times:')\n",
    "print(sensor_mi.loc['S2'].between_time('06:00', '09:00').head())"
   ],
   "id": "9eb5bf4746029bd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- sensor_mi (index sample) ---\n",
      "                               temperature   humidity\n",
      "sensor_id timestamp                                  \n",
      "S1        2025-11-01 00:00:00    11.844233  55.829533\n",
      "          2025-11-01 00:10:00    13.162956  55.409148\n",
      "          2025-11-01 00:20:00    10.544302  64.612578\n",
      "          2025-11-01 00:30:00          NaN  63.473544\n",
      "          2025-11-01 00:40:00    13.332673  63.221174\n",
      "\n",
      "Select all readings for S2 between two times:\n",
      "                     temperature   humidity\n",
      "timestamp                                  \n",
      "2025-11-01 06:00:00    16.292123  38.803557\n",
      "2025-11-01 06:10:00    16.560178  53.083026\n",
      "2025-11-01 06:20:00    15.860508  54.342884\n",
      "2025-11-01 06:30:00    14.793219  44.742754\n",
      "2025-11-01 06:40:00    16.511539  48.741353\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.508657Z",
     "start_time": "2025-11-17T15:27:43.495812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 3) Multi-level columns example: create aggregated summary with MultiIndex columns\n",
    "# -------------------------------\n",
    "agg_funcs = {\n",
    "'temperature': ['mean', 'std', 'min', 'max'],\n",
    "'humidity': ['mean', 'std']\n",
    "}\n",
    "summary_by_sensor = sensor_df.groupby('sensor_id').agg(agg_funcs)\n",
    "# flatten/unflatten demonstration: keep as MultiIndex columns\n",
    "print('\\n--- summary_by_sensor (MultiIndex columns) ---')\n",
    "print(summary_by_sensor.head())\n",
    "\n",
    "# rename columns to readable MultiIndex (level names)\n",
    "summary_by_sensor.columns.names = ['measurement', 'stat']\n",
    "print('\\nColumns levels:', summary_by_sensor.columns.names)\n",
    "\n",
    "# access a specific subtable using xs\n",
    "print('\\nTemperature means:')\n",
    "print(summary_by_sensor.xs('temperature', axis=1)[['mean', 'std']])"
   ],
   "id": "fe1f80f362ced9a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- summary_by_sensor (MultiIndex columns) ---\n",
      "          temperature                                  humidity          \n",
      "                 mean       std       min        max       mean       std\n",
      "sensor_id                                                                \n",
      "S1          16.718369  4.511676  8.552629  25.213955  59.259889  5.560005\n",
      "S2          15.427998  4.497470  2.122613  24.023564  45.599224  5.493384\n",
      "S3          15.658394  4.421943  7.273332  25.556400  56.385015  5.146519\n",
      "S4          15.668049  4.238744  7.365955  24.204889  48.812680  5.493305\n",
      "S5          17.801163  4.889507  9.133021  38.594542  49.913718  5.367881\n",
      "\n",
      "Columns levels: ['measurement', 'stat']\n",
      "\n",
      "Temperature means:\n",
      "stat            mean       std\n",
      "sensor_id                     \n",
      "S1         16.718369  4.511676\n",
      "S2         15.427998  4.497470\n",
      "S3         15.658394  4.421943\n",
      "S4         15.668049  4.238744\n",
      "S5         17.801163  4.889507\n",
      "S6         18.627710  4.633420\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.522159Z",
     "start_time": "2025-11-17T15:27:43.515566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summary_by_sensor.columns = [\n",
    "    f\"{measurement}_{stat}\"\n",
    "    for measurement, stat in summary_by_sensor.columns\n",
    "]\n",
    "\n",
    "print('\\n--- summary_by_sensor (flat columns) ---')\n",
    "print(summary_by_sensor.head())"
   ],
   "id": "6e3c22cd566ae71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- summary_by_sensor (flat columns) ---\n",
      "           temperature_mean  temperature_std  temperature_min  \\\n",
      "sensor_id                                                       \n",
      "S1                16.718369         4.511676         8.552629   \n",
      "S2                15.427998         4.497470         2.122613   \n",
      "S3                15.658394         4.421943         7.273332   \n",
      "S4                15.668049         4.238744         7.365955   \n",
      "S5                17.801163         4.889507         9.133021   \n",
      "\n",
      "           temperature_max  humidity_mean  humidity_std  \n",
      "sensor_id                                                \n",
      "S1               25.213955      59.259889      5.560005  \n",
      "S2               24.023564      45.599224      5.493384  \n",
      "S3               25.556400      56.385015      5.146519  \n",
      "S4               24.204889      48.812680      5.493305  \n",
      "S5               38.594542      49.913718      5.367881  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.556364Z",
     "start_time": "2025-11-17T15:27:43.530814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 4) Advanced groupby with named aggregation and custom functions\n",
    "# -------------------------------\n",
    "# We'll compute per-sensor and per-location aggregations using named aggregations\n",
    "sensor_with_meta = sensor_df.merge(meta, on='sensor_id', how='left')\n",
    "\n",
    "agg_named = sensor_with_meta.groupby(['location']).agg(\n",
    "temp_mean=('temperature', 'mean'),\n",
    "temp_med=('temperature', 'median'),\n",
    "temp_iqr=('temperature', lambda x: np.subtract(*np.percentile(x.dropna(), [75, 25]))),\n",
    "humidity_mean=('humidity', 'mean'),\n",
    "n_readings=('temperature', 'count')\n",
    ")\n",
    "print('\\n--- agg_named by location ---')\n",
    "print(agg_named)\n",
    "\n",
    "# custom aggregation using apply (slower but expressive) -> compute time-of-day sensitivity\n",
    "\n",
    "def day_night_diff(group):\n",
    "    group = group.copy()\n",
    "    # daytime mean vs nighttime mean\n",
    "    group['hour'] = group['timestamp'].dt.hour\n",
    "    daytime = group.loc[(group['hour'] >= 6) & (group['hour'] < 18), 'temperature']\n",
    "    nighttime = group.loc[(group['hour'] < 6) | (group['hour'] >= 18), 'temperature']\n",
    "    return pd.Series({'day_minus_night': daytime.mean() - nighttime.mean()})\n",
    "\n",
    "sens_daynight = sensor_df.merge(meta, on='sensor_id').groupby('sensor_id').apply(day_night_diff, include_groups=False)\n",
    "print('\\n--- day_minus_night per sensor ---')\n",
    "print(sens_daynight.head())"
   ],
   "id": "154d5431892d067b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- agg_named by location ---\n",
      "          temp_mean   temp_med  temp_iqr  humidity_mean  n_readings\n",
      "location                                                           \n",
      "Room A    16.187642  16.260233  7.800304      54.036285         283\n",
      "Room B    17.022280  16.570175  7.810141      48.698361         287\n",
      "Room C    15.658394  15.917286  8.167460      56.385015         143\n",
      "Room D    17.801163  18.022922  8.284296      49.913718         142\n",
      "\n",
      "--- day_minus_night per sensor ---\n",
      "           day_minus_night\n",
      "sensor_id                 \n",
      "S1                7.691988\n",
      "S2                7.222448\n",
      "S3                7.461552\n",
      "S4                7.165945\n",
      "S5                7.980190\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.572755Z",
     "start_time": "2025-11-17T15:27:43.570432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Note on merge vs join\n",
    "# pandas.merge() is the core function for all merges/joins.\n",
    "# df.merge() and df.join() are convenient wrappers:\n",
    "# - df.join() defaults to left join on df1's index and df2's index.\n",
    "# - df.merge() defaults to inner join on columns, but can join on indexes.\n",
    "# Use merge() for flexibility; join() can save typing in simple index-based left joins."
   ],
   "id": "494bd5820fa96968",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.597671Z",
     "start_time": "2025-11-17T15:27:43.579254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 5) pivot_table & crosstab\n",
    "# -------------------------------\n",
    "# pivot_table: average temperature per sensor per hour of day\n",
    "sensor_df['hour'] = sensor_df['timestamp'].dt.hour\n",
    "pv = pd.pivot_table(sensor_df, values='temperature', index='sensor_id', columns='hour', aggfunc='mean')\n",
    "print('\\n--- pivot_table mean temperature by sensor x hour ---')\n",
    "print(pv.iloc[:, :6]) # show first 6 hours as sample\n",
    "\n",
    "# crosstab: count of readings per sensor per type\n",
    "sensor_meta_joined = sensor_df.merge(meta, on='sensor_id')\n",
    "ct = pd.crosstab(sensor_meta_joined['sensor_id'], sensor_meta_joined['type'])\n",
    "print('\\n--- crosstab counts sensor x type ---')\n",
    "print(ct)"
   ],
   "id": "fe5994710a45439a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- pivot_table mean temperature by sensor x hour ---\n",
      "hour               0          1          2          3          4          5\n",
      "sensor_id                                                                  \n",
      "S1         12.210048  10.664322  10.720927  12.989877  14.358660  14.856285\n",
      "S2          9.690962  10.132154  10.812555  12.572447  13.260633  14.696669\n",
      "S3         10.254658  10.215027  10.674089  13.038813  12.860999  15.427306\n",
      "S4          9.326482  10.789089  11.722838  13.088461  13.111283  14.757508\n",
      "S5         12.241501  12.651350  11.540636  13.750657  14.472117  16.459888\n",
      "S6         13.411637  12.972633  14.169101  15.001611  16.085027  17.580157\n",
      "\n",
      "--- crosstab counts sensor x type ---\n",
      "type       hygro  thermo  thermo-hygro\n",
      "sensor_id                             \n",
      "S1             0       0           144\n",
      "S2             0       0           144\n",
      "S3             0     144             0\n",
      "S4             0       0           144\n",
      "S5           144       0             0\n",
      "S6             0     144             0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.630238Z",
     "start_time": "2025-11-17T15:27:43.604191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 6) Merging and joining examples (all possibilities)\n",
    "# -------------------------------\n",
    "# inner merge (only sensors present in both)\n",
    "m_inner = sensor_df.merge(meta, on='sensor_id', how='inner')\n",
    "# left merge (keeps all readings)\n",
    "m_left = sensor_df.merge(meta, on='sensor_id', how='left')\n",
    "# right and outer\n",
    "m_right = sensor_df.merge(meta, on='sensor_id', how='right')\n",
    "m_outer = sensor_df.merge(meta, on='sensor_id', how='outer')\n",
    "\n",
    "print('\\nmerge sizes: inner={}, left={}, right={}, outer={}'.format(\n",
    "len(m_inner), len(m_left), len(m_right), len(m_outer)\n",
    "))\n",
    "\n",
    "# join on index: prepare two DataFrames with indexes\n",
    "df_a = sensor_df.sample(50, random_state=4).set_index(['sensor_id', 'timestamp']).sort_index()\n",
    "df_b = pd.DataFrame({'battery': np.random.randint(20, 100, size=30)},\n",
    "index=df_a.index[:30])\n",
    "# left join using index\n",
    "joined = df_a.join(df_b, how='left')\n",
    "\n",
    "print('\\n--- joined (index join) sample ---')\n",
    "print(joined.head())\n",
    "\n",
    "# concat: stack vertically and horizontally\n",
    "concat_v = pd.concat([sensor_df.head(5), sensor_df.tail(5)], axis=0)\n",
    "concat_h = pd.concat([sensor_df.head(5).reset_index(drop=True).iloc[:, :3],\n",
    "sensor_df.head(5).reset_index(drop=True).iloc[:, 3:]], axis=1)\n",
    "\n",
    "# combine_first: combine two sources preferring left's non-null values\n",
    "left = sensor_df.head(10).copy()\n",
    "right = left.copy()\n",
    "right.loc[right.sample(frac=0.3, random_state=5).index, 'temperature'] = np.nan\n",
    "combined = right.combine_first(left)\n",
    "print('\\n--- combine_first example ---')\n",
    "print(combined.head())"
   ],
   "id": "defb4726e24e493a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merge sizes: inner=864, left=864, right=864, outer=864\n",
      "\n",
      "--- joined (index join) sample ---\n",
      "                               temperature   humidity  hour  battery\n",
      "sensor_id timestamp                                                 \n",
      "S1        2025-11-01 07:50:00    16.998632  51.400346     7     74.0\n",
      "          2025-11-01 10:30:00    24.450338  75.506305    10     35.0\n",
      "          2025-11-01 11:00:00    23.210710  60.886517    11     81.0\n",
      "          2025-11-01 11:10:00    21.762797  59.342354    11     67.0\n",
      "          2025-11-01 11:40:00    22.796130  52.161576    11     49.0\n",
      "\n",
      "--- combine_first example ---\n",
      "  sensor_id           timestamp  temperature   humidity  hour\n",
      "0        S1 2025-11-01 00:00:00    11.844233  55.829533     0\n",
      "1        S1 2025-11-01 00:10:00    13.162956  55.409148     0\n",
      "2        S1 2025-11-01 00:20:00    10.544302  64.612578     0\n",
      "3        S1 2025-11-01 00:30:00          NaN  63.473544     0\n",
      "4        S1 2025-11-01 00:40:00    13.332673  63.221174     0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.649046Z",
     "start_time": "2025-11-17T15:27:43.635988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 7) Reshaping: stack/unstack and melt\n",
    "# -------------------------------\n",
    "# create a small pivot and show stack/unstack\n",
    "small = sensor_df[sensor_df['sensor_id'].isin(['S1', 'S2'])].head(12)\n",
    "pv_small = small.pivot(index='timestamp', columns='sensor_id', values='temperature')\n",
    "print('\\n--- pv_small pivot (timestamp x sensor) ---')\n",
    "print(pv_small.head())\n",
    "print('\\nstacked -> unstacked roundtrip (demonstration)')\n",
    "stacked = pv_small.stack()\n",
    "print(stacked.head())\n",
    "print(stacked.unstack().head())\n",
    "\n",
    "# melt: convert wide back to long\n",
    "melted = pv_small.reset_index().melt(id_vars='timestamp', var_name='sensor_id', value_name='temperature')\n",
    "print('\\n--- melted back to long ---')\n",
    "print(melted.head())"
   ],
   "id": "b66643a8f75af77e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- pv_small pivot (timestamp x sensor) ---\n",
      "sensor_id                   S1\n",
      "timestamp                     \n",
      "2025-11-01 00:00:00  11.844233\n",
      "2025-11-01 00:10:00  13.162956\n",
      "2025-11-01 00:20:00  10.544302\n",
      "2025-11-01 00:30:00        NaN\n",
      "2025-11-01 00:40:00  13.332673\n",
      "\n",
      "stacked -> unstacked roundtrip (demonstration)\n",
      "timestamp            sensor_id\n",
      "2025-11-01 00:00:00  S1           11.844233\n",
      "2025-11-01 00:10:00  S1           13.162956\n",
      "2025-11-01 00:20:00  S1           10.544302\n",
      "2025-11-01 00:40:00  S1           13.332673\n",
      "2025-11-01 00:50:00  S1           12.166077\n",
      "dtype: float64\n",
      "sensor_id                   S1\n",
      "timestamp                     \n",
      "2025-11-01 00:00:00  11.844233\n",
      "2025-11-01 00:10:00  13.162956\n",
      "2025-11-01 00:20:00  10.544302\n",
      "2025-11-01 00:40:00  13.332673\n",
      "2025-11-01 00:50:00  12.166077\n",
      "\n",
      "--- melted back to long ---\n",
      "            timestamp sensor_id  temperature\n",
      "0 2025-11-01 00:00:00        S1    11.844233\n",
      "1 2025-11-01 00:10:00        S1    13.162956\n",
      "2 2025-11-01 00:20:00        S1    10.544302\n",
      "3 2025-11-01 00:30:00        S1          NaN\n",
      "4 2025-11-01 00:40:00        S1    13.332673\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.664993Z",
     "start_time": "2025-11-17T15:27:43.656053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 8) Query: expressive filtering\n",
    "# -------------------------------\n",
    "# Use DataFrame.query for readable boolean expressions\n",
    "q = sensor_df.query('temperature > 25 and humidity < 50')\n",
    "print(f'\\nNumber of readings with temperature>25 and humidity<50: {len(q)}')\n",
    "\n",
    "# boolean indexing vs query for more complex expressions\n",
    "expr = \"(temperature > temperature.mean()) & (humidity < humidity.quantile(0.25))\"\n",
    "# careful: can't use temperature.mean() inside query easily; compute first\n",
    "temp_mean = sensor_df['temperature'].mean()\n",
    "hum_q25 = sensor_df['humidity'].quantile(0.25)\n",
    "q2 = sensor_df.query('@temp_mean < temperature and humidity < @hum_q25')\n",
    "print(f'\\nUsing external variables in query, matches: {len(q2)}')"
   ],
   "id": "a852e0f035cc0560",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of readings with temperature>25 and humidity<50: 12\n",
      "\n",
      "Using external variables in query, matches: 139\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.698759Z",
     "start_time": "2025-11-17T15:27:43.684336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 9) Aggregations with groupby + transform and filter\n",
    "# -------------------------------\n",
    "# find sensors whose median temperature is > global median\n",
    "global_median = sensor_df['temperature'].median()\n",
    "sensor_medians = sensor_df.groupby('sensor_id')['temperature'].median()\n",
    "hot_sensors = sensor_medians[sensor_medians > global_median].index.tolist()\n",
    "print('\\nSensors with median temperature > global median:', hot_sensors)\n",
    "\n",
    "# use transform to broadcast group statistic back to rows\n",
    "sensor_df['sensor_temp_median'] = sensor_df.groupby('sensor_id')['temperature'].transform('median')\n",
    "# filter rows where temperature is above group's median\n",
    "above_group_median = sensor_df[sensor_df['temperature'] > sensor_df['sensor_temp_median']]\n",
    "print('\\nRows above their sensor median (sample):')\n",
    "print(above_group_median.head())\n",
    "\n",
    "# groupby.filter to keep only sensors with at least 200 readings\n",
    "sensors_with_enough = sensor_df.groupby('sensor_id').filter(lambda g: len(g) >= 200)\n",
    "print('\\nSensors kept (len>=200):', sensors_with_enough['sensor_id'].unique())"
   ],
   "id": "803358e497f5efa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensors with median temperature > global median: ['S1', 'S5', 'S6']\n",
      "\n",
      "Rows above their sensor median (sample):\n",
      "   sensor_id           timestamp  temperature   humidity  hour  \\\n",
      "29        S1 2025-11-01 04:50:00    17.846883  64.052320     4   \n",
      "32        S1 2025-11-01 05:20:00    17.064629  58.211946     5   \n",
      "37        S1 2025-11-01 06:10:00    17.429709  61.295790     6   \n",
      "38        S1 2025-11-01 06:20:00    18.503335  57.635505     6   \n",
      "39        S1 2025-11-01 06:30:00    17.912910  62.192710     6   \n",
      "\n",
      "    sensor_temp_median  \n",
      "29            17.01069  \n",
      "32            17.01069  \n",
      "37            17.01069  \n",
      "38            17.01069  \n",
      "39            17.01069  \n",
      "\n",
      "Sensors kept (len>=200): []\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.717130Z",
     "start_time": "2025-11-17T15:27:43.705867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 10) MultiIndex columns: produce aggregated table with hierarchical columns and plot\n",
    "# -------------------------------\n",
    "agg_multi = sensor_df.groupby('sensor_id').agg(\n",
    "temp_mean=('temperature', 'mean'),\n",
    "temp_std=('temperature', 'std'),\n",
    "hum_mean=('humidity', 'mean'),\n",
    "hum_std=('humidity', 'std')\n",
    ")\n",
    "# create MultiIndex columns manually\n",
    "agg_multi.columns = pd.MultiIndex.from_tuples([('temperature', 'mean'), ('temperature', 'std'), ('humidity', 'mean'), ('humidity', 'std')])\n",
    "print('\\n--- agg_multi (MultiIndex columns) ---')\n",
    "print(agg_multi)"
   ],
   "id": "f042061cbb13ae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- agg_multi (MultiIndex columns) ---\n",
      "          temperature             humidity          \n",
      "                 mean       std       mean       std\n",
      "sensor_id                                           \n",
      "S1          16.718369  4.511676  59.259889  5.560005\n",
      "S2          15.427998  4.497470  45.599224  5.493384\n",
      "S3          15.658394  4.421943  56.385015  5.146519\n",
      "S4          15.668049  4.238744  48.812680  5.493305\n",
      "S5          17.801163  4.889507  49.913718  5.367881\n",
      "S6          18.627710  4.633420  51.732933  5.117629\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.735393Z",
     "start_time": "2025-11-17T15:27:43.727547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# 11) Rolling, expanding and time-based resampling (for sensor S2)\n",
    "# -------------------------------\n",
    "s2 = sensor_df[sensor_df['sensor_id'] == 'S2'].set_index('timestamp').sort_index()\n",
    "# rolling 30-minute window (freq is 10min so 3 observations -> use time-based window)\n",
    "s2['temp_roll_30min'] = s2['temperature'].rolling('30min').mean()\n",
    "# humidity diff next reading -> shift(-1)\n",
    "s2['humidity_next_diff'] = s2['humidity'].shift(-1) - s2['humidity']\n",
    "# boolean: temp increased >5C and humidity dropped >20 compared to previous measurement\n",
    "s2['temp_prev_diff'] = s2['temperature'] - s2['temperature'].shift(1)\n",
    "s2['hum_prev_diff'] = s2['humidity'].shift(1) - s2['humidity']\n",
    "s2['extreme_change'] = (s2['temp_prev_diff'] > 5) & (s2['hum_prev_diff'] > 20)"
   ],
   "id": "2652a22c929c768d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task Specification: Aggregations, Joins, GroupBy, and Rolling Analysis with Pandas\n",
    "\n",
    "---\n",
    "\n",
    "### **Task Overview**\n",
    "This assignment simulates a **customer purchase analytics workflow** using Pandas. You will work with timestamped transaction data and customer metadata, performing:\n",
    "\n",
    "- Group-based aggregations\n",
    "- Time-based analysis\n",
    "- Rolling window calculations within groups\n",
    "- Joining customer metadata from another dataset\n",
    "\n",
    "---\n",
    "\n",
    "### **Datasets**\n",
    "You are provided with two datasets:\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `data/purchases.csv` | Timestamped purchase data (contains `Customer_id`, `Timestamp`, `Price`, etc.) |\n",
    "| `data/customer_info.csv` | Customer metadata (contains `Customer_id`, `Born_date`, `City`, etc.) |\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Load and Prepare the Data**\n",
    "- **Task 1.1:** Load the two CSV files into Pandas DataFrames:\n",
    "  - Use `df` for `purchases.csv`\n",
    "  - Use `customer_info` for `customer_info.csv`\n",
    "\n",
    "- **Task 1.2:** Convert the `Timestamp` column in `df` to Pandas `datetime` format.\n",
    "\n",
    "- **Task 1.3:** Set `Timestamp` as the **index** of `df` and **sort** the index in ascending order.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Join Customer Metadata**\n",
    "- **Task 2.1:** Merge the purchase DataFrame (`df`) with the customer metadata DataFrame (`customer_info`) on the `Customer_id` column.\n",
    "\n",
    "- **Task 2.2:** The resulting DataFrame should include the columns `Born_date` and `City` from the `customer_info` DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. GroupBy and Aggregations**\n",
    "Using the merged DataFrame:\n",
    "\n",
    "- **Task 3.1:** Group by **Customer_id** and compute:\n",
    "  - Total revenue (`sum(Price)`)\n",
    "  - Number of purchases (`count`)\n",
    "  - Average purchase price (`mean(Price)`)\n",
    "\n",
    "- **Task 3.2:** Create a new feature by extracting the **month name** (e.g., `\"January\"`, `\"February\"`) from the `Timestamp`.\n",
    "\n",
    "- **Task 3.3:** Group by **City** and **Month** and compute:\n",
    "  - Total monthly revenue per city (`sum(Price)`)\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Rolling Window Analysis (Per Customer)**\n",
    "Perform rolling window calculations **within each customer group**:\n",
    "\n",
    "- Inside each customer group:\n",
    "  - **Sort** the DataFrame by `Timestamp`.\n",
    "\n",
    "- Compute the following:\n",
    "  - A **3-purchase rolling average** of `Price`.\n",
    "  - A `diff()` column showing the change in price compared to the previous purchase.\n",
    "\n",
    "> **Note:** The rolling operations must be computed **within each customer group**, not across all customers.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Advanced Filtering**\n",
    "- Do the same as in 4 only for customers from **Berlin**, make sure only necessary values are joined (that is filter first, join second).\n",
    "\n",
    "- Do the same as in 4 only for rows where the `Price` of the current purchase is greater than **20%** than the previous purchase (`Price`), make sure only necessary values are joined (that is filter first, join second).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Custom Lambda Function for GroupBy Operations**\n",
    "- Apply a **custom lambda function** within a `groupby()` operation to filter or modify the data. For example:\n",
    "  - Use a lambda to **filter** customers who have purchased more than a specific amount within a given timeframe (e.g., greater than $1000 in total purchases during the last quarter).\n",
    "  - Apply custom transformations to grouped data using the lambda function.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Time-Based Analysis\n",
    "- Perform additional time-based analysis:\n",
    "  - Calculate **monthly growth rate** for total revenue per customer (i.e., compare total revenue of the current month with the previous month).\n",
    "  - Create a **cumulative sum** of purchases over time per customer.\n"
   ],
   "id": "7869d828038909f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.760729Z",
     "start_time": "2025-11-17T15:27:43.742861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"1.1\")\n",
    "df=pd.read_csv('data/purchases.csv')\n",
    "print(df.columns)\n",
    "customer_info=pd.read_csv('data/customer_info.csv')\n",
    "print(customer_info.columns)\n",
    "\n",
    "print(\"1.2\")\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp']) #turns elements of timestamp into date time type\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"1.3\")\n",
    "df.set_index('Timestamp', inplace=True) #sets the index of dataframe to Timestamp\n",
    "df.sort_index(ascending=True, inplace=True) #sorts the dataframe by the ascending index Timestamp\n",
    "print(df.head())\n",
    "df.reset_index(inplace=True) #resets the index so the column is included in merged dataframes"
   ],
   "id": "f0bbbc45e8d9f1fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "Index(['Customer_id', 'Timestamp', 'Price'], dtype='object')\n",
      "Index(['Customer_id', 'Born_date', 'City'], dtype='object')\n",
      "1.2\n",
      "Customer_id            object\n",
      "Timestamp      datetime64[ns]\n",
      "Price                 float64\n",
      "dtype: object\n",
      "1.3\n",
      "                    Customer_id   Price\n",
      "Timestamp                              \n",
      "2025-01-01 00:00:00        C037  436.71\n",
      "2025-01-01 00:30:00        C049  274.70\n",
      "2025-01-01 01:00:00        C017  380.42\n",
      "2025-01-01 01:30:00        C049  378.28\n",
      "2025-01-01 02:00:00        C002   13.88\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.775228Z",
     "start_time": "2025-11-17T15:27:43.767352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"2.\")\n",
    "dfmerged = df.merge(customer_info, on='Customer_id') #merges df and customer_info data frames through customer id\n",
    "print(dfmerged.head())\n"
   ],
   "id": "509b8d75c1cbebe7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.\n",
      "            Timestamp Customer_id   Price   Born_date       City\n",
      "0 2025-01-01 00:00:00        C037  436.71  1996-09-14     Munich\n",
      "1 2025-01-01 00:30:00        C049  274.70  1979-01-20     Munich\n",
      "2 2025-01-01 01:00:00        C017  380.42  1981-02-23    Cologne\n",
      "3 2025-01-01 01:30:00        C049  378.28  1979-01-20     Munich\n",
      "4 2025-01-01 02:00:00        C002   13.88  1988-07-03  Frankfurt\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.799387Z",
     "start_time": "2025-11-17T15:27:43.781078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"3.1\")\n",
    "agg_fce = {\n",
    "'Price': ['sum', 'count', 'mean']\n",
    "} #functions we want to use\n",
    "dfmerged.groupby('Customer_id').agg(agg_fce) #groups the dataframe by customer id and for each id counts the sum, mean and count of price"
   ],
   "id": "c241edd74ee5cb26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                Price                  \n",
       "                  sum count        mean\n",
       "Customer_id                            \n",
       "C001         13055.75    56  233.138393\n",
       "C002         15927.80    64  248.871875\n",
       "C003         14947.34    56  266.916786\n",
       "C004         15111.43    59  256.125932\n",
       "C005         16798.61    64  262.478281\n",
       "C006         14774.24    63  234.511746\n",
       "C007         11886.07    48  247.626458\n",
       "C008         15555.66    65  239.317846\n",
       "C009         12630.37    52  242.891731\n",
       "C010         17554.93    61  287.785738\n",
       "C011         15360.64    58  264.838621\n",
       "C012         15547.49    61  254.876885\n",
       "C013         14548.85    57  255.242982\n",
       "C014         12758.90    57  223.840351\n",
       "C015         15948.56    57  279.799298\n",
       "C016         14485.74    54  268.254444\n",
       "C017         16645.31    64  260.082969\n",
       "C018         14808.21    58  255.313966\n",
       "C019         13761.40    54  254.840741\n",
       "C020         14716.58    59  249.433559\n",
       "C021         17883.33    70  255.476143\n",
       "C022         14539.21    64  227.175156\n",
       "C023         17083.52    62  275.540645\n",
       "C024         12874.62    60  214.577000\n",
       "C025         17992.97    71  253.422113\n",
       "C026         20125.68    73  275.694247\n",
       "C027          8229.66    40  205.741500\n",
       "C028         14887.75    59  252.334746\n",
       "C029         16221.78    67  242.116119\n",
       "C030         15262.94    61  250.212131\n",
       "C031         12570.34    50  251.406800\n",
       "C032         19472.61    68  286.361912\n",
       "C033         17206.77    69  249.373478\n",
       "C034         17753.22    65  273.126462\n",
       "C035         17772.63    71  250.318732\n",
       "C036         16332.65    64  255.197656\n",
       "C037         18718.80    71  263.645070\n",
       "C038         12993.52    53  245.160755\n",
       "C039         16494.77    58  284.392586\n",
       "C040         15002.15    59  254.273729\n",
       "C041         14666.49    53  276.726226\n",
       "C042         13617.03    52  261.865962\n",
       "C043         12360.38    46  268.703913\n",
       "C044         13990.66    58  241.218276\n",
       "C045         15453.54    65  237.746769\n",
       "C046         14241.93    55  258.944182\n",
       "C047         15839.03    69  229.551159\n",
       "C048         12138.76    47  258.271489\n",
       "C049         18120.74    74  244.874865\n",
       "C050         12643.75    59  214.300847"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C001</th>\n",
       "      <td>13055.75</td>\n",
       "      <td>56</td>\n",
       "      <td>233.138393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C002</th>\n",
       "      <td>15927.80</td>\n",
       "      <td>64</td>\n",
       "      <td>248.871875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C003</th>\n",
       "      <td>14947.34</td>\n",
       "      <td>56</td>\n",
       "      <td>266.916786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C004</th>\n",
       "      <td>15111.43</td>\n",
       "      <td>59</td>\n",
       "      <td>256.125932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C005</th>\n",
       "      <td>16798.61</td>\n",
       "      <td>64</td>\n",
       "      <td>262.478281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C006</th>\n",
       "      <td>14774.24</td>\n",
       "      <td>63</td>\n",
       "      <td>234.511746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C007</th>\n",
       "      <td>11886.07</td>\n",
       "      <td>48</td>\n",
       "      <td>247.626458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C008</th>\n",
       "      <td>15555.66</td>\n",
       "      <td>65</td>\n",
       "      <td>239.317846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C009</th>\n",
       "      <td>12630.37</td>\n",
       "      <td>52</td>\n",
       "      <td>242.891731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C010</th>\n",
       "      <td>17554.93</td>\n",
       "      <td>61</td>\n",
       "      <td>287.785738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C011</th>\n",
       "      <td>15360.64</td>\n",
       "      <td>58</td>\n",
       "      <td>264.838621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C012</th>\n",
       "      <td>15547.49</td>\n",
       "      <td>61</td>\n",
       "      <td>254.876885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C013</th>\n",
       "      <td>14548.85</td>\n",
       "      <td>57</td>\n",
       "      <td>255.242982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C014</th>\n",
       "      <td>12758.90</td>\n",
       "      <td>57</td>\n",
       "      <td>223.840351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C015</th>\n",
       "      <td>15948.56</td>\n",
       "      <td>57</td>\n",
       "      <td>279.799298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C016</th>\n",
       "      <td>14485.74</td>\n",
       "      <td>54</td>\n",
       "      <td>268.254444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C017</th>\n",
       "      <td>16645.31</td>\n",
       "      <td>64</td>\n",
       "      <td>260.082969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C018</th>\n",
       "      <td>14808.21</td>\n",
       "      <td>58</td>\n",
       "      <td>255.313966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C019</th>\n",
       "      <td>13761.40</td>\n",
       "      <td>54</td>\n",
       "      <td>254.840741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C020</th>\n",
       "      <td>14716.58</td>\n",
       "      <td>59</td>\n",
       "      <td>249.433559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C021</th>\n",
       "      <td>17883.33</td>\n",
       "      <td>70</td>\n",
       "      <td>255.476143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C022</th>\n",
       "      <td>14539.21</td>\n",
       "      <td>64</td>\n",
       "      <td>227.175156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C023</th>\n",
       "      <td>17083.52</td>\n",
       "      <td>62</td>\n",
       "      <td>275.540645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C024</th>\n",
       "      <td>12874.62</td>\n",
       "      <td>60</td>\n",
       "      <td>214.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C025</th>\n",
       "      <td>17992.97</td>\n",
       "      <td>71</td>\n",
       "      <td>253.422113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C026</th>\n",
       "      <td>20125.68</td>\n",
       "      <td>73</td>\n",
       "      <td>275.694247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C027</th>\n",
       "      <td>8229.66</td>\n",
       "      <td>40</td>\n",
       "      <td>205.741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C028</th>\n",
       "      <td>14887.75</td>\n",
       "      <td>59</td>\n",
       "      <td>252.334746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C029</th>\n",
       "      <td>16221.78</td>\n",
       "      <td>67</td>\n",
       "      <td>242.116119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C030</th>\n",
       "      <td>15262.94</td>\n",
       "      <td>61</td>\n",
       "      <td>250.212131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C031</th>\n",
       "      <td>12570.34</td>\n",
       "      <td>50</td>\n",
       "      <td>251.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C032</th>\n",
       "      <td>19472.61</td>\n",
       "      <td>68</td>\n",
       "      <td>286.361912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C033</th>\n",
       "      <td>17206.77</td>\n",
       "      <td>69</td>\n",
       "      <td>249.373478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C034</th>\n",
       "      <td>17753.22</td>\n",
       "      <td>65</td>\n",
       "      <td>273.126462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C035</th>\n",
       "      <td>17772.63</td>\n",
       "      <td>71</td>\n",
       "      <td>250.318732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C036</th>\n",
       "      <td>16332.65</td>\n",
       "      <td>64</td>\n",
       "      <td>255.197656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C037</th>\n",
       "      <td>18718.80</td>\n",
       "      <td>71</td>\n",
       "      <td>263.645070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C038</th>\n",
       "      <td>12993.52</td>\n",
       "      <td>53</td>\n",
       "      <td>245.160755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C039</th>\n",
       "      <td>16494.77</td>\n",
       "      <td>58</td>\n",
       "      <td>284.392586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C040</th>\n",
       "      <td>15002.15</td>\n",
       "      <td>59</td>\n",
       "      <td>254.273729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C041</th>\n",
       "      <td>14666.49</td>\n",
       "      <td>53</td>\n",
       "      <td>276.726226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C042</th>\n",
       "      <td>13617.03</td>\n",
       "      <td>52</td>\n",
       "      <td>261.865962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C043</th>\n",
       "      <td>12360.38</td>\n",
       "      <td>46</td>\n",
       "      <td>268.703913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C044</th>\n",
       "      <td>13990.66</td>\n",
       "      <td>58</td>\n",
       "      <td>241.218276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C045</th>\n",
       "      <td>15453.54</td>\n",
       "      <td>65</td>\n",
       "      <td>237.746769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C046</th>\n",
       "      <td>14241.93</td>\n",
       "      <td>55</td>\n",
       "      <td>258.944182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C047</th>\n",
       "      <td>15839.03</td>\n",
       "      <td>69</td>\n",
       "      <td>229.551159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C048</th>\n",
       "      <td>12138.76</td>\n",
       "      <td>47</td>\n",
       "      <td>258.271489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C049</th>\n",
       "      <td>18120.74</td>\n",
       "      <td>74</td>\n",
       "      <td>244.874865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C050</th>\n",
       "      <td>12643.75</td>\n",
       "      <td>59</td>\n",
       "      <td>214.300847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.836987Z",
     "start_time": "2025-11-17T15:27:43.820750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"3.2\")\n",
    "dfmerged['Month'] = dfmerged['Timestamp'].dt.month_name() #creates new column with month names\n",
    "print(dfmerged.head())\n",
    "\n",
    "print(\"3.3\")\n",
    "dfmerged.groupby(['City','Month']).agg(sum =('Price', 'sum')) #groups the data frame into cities and months for each city and calculates the sum price for each month in each city"
   ],
   "id": "a553ce4656a4e0e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2\n",
      "            Timestamp Customer_id   Price   Born_date       City    Month\n",
      "0 2025-01-01 00:00:00        C037  436.71  1996-09-14     Munich  January\n",
      "1 2025-01-01 00:30:00        C049  274.70  1979-01-20     Munich  January\n",
      "2 2025-01-01 01:00:00        C017  380.42  1981-02-23    Cologne  January\n",
      "3 2025-01-01 01:30:00        C049  378.28  1979-01-20     Munich  January\n",
      "4 2025-01-01 02:00:00        C002   13.88  1988-07-03  Frankfurt  January\n",
      "3.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                          sum\n",
       "City      Month              \n",
       "Berlin    February   86163.85\n",
       "          January   101192.17\n",
       "          March      10474.86\n",
       "Cologne   February   86781.31\n",
       "          January    98030.00\n",
       "          March      11220.64\n",
       "Frankfurt February   52020.01\n",
       "          January    61492.29\n",
       "          March       6698.88\n",
       "Hamburg   February   42056.17\n",
       "          January    43988.43\n",
       "          March       5340.12\n",
       "Munich    February   67799.84\n",
       "          January    78726.19\n",
       "          March       7330.35"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Berlin</th>\n",
       "      <th>February</th>\n",
       "      <td>86163.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>101192.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>10474.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Cologne</th>\n",
       "      <th>February</th>\n",
       "      <td>86781.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>98030.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>11220.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Frankfurt</th>\n",
       "      <th>February</th>\n",
       "      <td>52020.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>61492.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>6698.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Hamburg</th>\n",
       "      <th>February</th>\n",
       "      <td>42056.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>43988.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>5340.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Munich</th>\n",
       "      <th>February</th>\n",
       "      <td>67799.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>78726.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>7330.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.857698Z",
     "start_time": "2025-11-17T15:27:43.843081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"4.1\")\n",
    "dfmerged.set_index(['Customer_id','Timestamp'], inplace=True) #sets the index of dataframe to customer id and timestamp\n",
    "dfmerged.sort_index(ascending=True, inplace=True) #sorts the dataframe by Timestamp\n",
    "dfmerged\n",
    "\n"
   ],
   "id": "ce0ac2e5d169be91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date       City     Month\n",
       "Customer_id Timestamp                                                   \n",
       "C001        2025-01-01 05:30:00  376.61  1998-12-03  Frankfurt   January\n",
       "            2025-01-02 02:00:00   63.23  1998-12-03  Frankfurt   January\n",
       "            2025-01-02 10:00:00  108.83  1998-12-03  Frankfurt   January\n",
       "            2025-01-05 05:00:00   70.19  1998-12-03  Frankfurt   January\n",
       "            2025-01-06 07:00:00  132.80  1998-12-03  Frankfurt   January\n",
       "...                                 ...         ...        ...       ...\n",
       "C050        2025-02-26 06:30:00  269.66  1987-08-04     Berlin  February\n",
       "            2025-03-01 07:30:00  154.22  1987-08-04     Berlin     March\n",
       "            2025-03-01 22:00:00  492.96  1987-08-04     Berlin     March\n",
       "            2025-03-02 20:00:00  248.72  1987-08-04     Berlin     March\n",
       "            2025-03-03 13:30:00  136.22  1987-08-04     Berlin     March\n",
       "\n",
       "[3000 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C001</th>\n",
       "      <th>2025-01-01 05:30:00</th>\n",
       "      <td>376.61</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 02:00:00</th>\n",
       "      <td>63.23</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 10:00:00</th>\n",
       "      <td>108.83</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05 05:00:00</th>\n",
       "      <td>70.19</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:00:00</th>\n",
       "      <td>132.80</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>269.66</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 07:30:00</th>\n",
       "      <td>154.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>492.96</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>248.72</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 13:30:00</th>\n",
       "      <td>136.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.928604Z",
     "start_time": "2025-11-17T15:27:43.910367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"4.2\")\n",
    "dfmerged['3_purchase_rolling_average']=dfmerged.groupby('Customer_id')['Price'].rolling(3).mean().reset_index(level=0,drop=True) #groups dataframe by cuctomer id, selects only column price, creates rolling window of 3 rows within each customer group calculates mean and resets the rolling window on nw customer id\n",
    "dfmerged['diff']=dfmerged['Price'] - dfmerged['Price'].shift(1) # makes a new column with the difference\n",
    "dfmerged"
   ],
   "id": "9010c181312a2bfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date       City     Month  \\\n",
       "Customer_id Timestamp                                                      \n",
       "C001        2025-01-01 05:30:00  376.61  1998-12-03  Frankfurt   January   \n",
       "            2025-01-02 02:00:00   63.23  1998-12-03  Frankfurt   January   \n",
       "            2025-01-02 10:00:00  108.83  1998-12-03  Frankfurt   January   \n",
       "            2025-01-05 05:00:00   70.19  1998-12-03  Frankfurt   January   \n",
       "            2025-01-06 07:00:00  132.80  1998-12-03  Frankfurt   January   \n",
       "...                                 ...         ...        ...       ...   \n",
       "C050        2025-02-26 06:30:00  269.66  1987-08-04     Berlin  February   \n",
       "            2025-03-01 07:30:00  154.22  1987-08-04     Berlin     March   \n",
       "            2025-03-01 22:00:00  492.96  1987-08-04     Berlin     March   \n",
       "            2025-03-02 20:00:00  248.72  1987-08-04     Berlin     March   \n",
       "            2025-03-03 13:30:00  136.22  1987-08-04     Berlin     March   \n",
       "\n",
       "                                 3_purchase_rolling_average    diff  \n",
       "Customer_id Timestamp                                                \n",
       "C001        2025-01-01 05:30:00                         NaN     NaN  \n",
       "            2025-01-02 02:00:00                         NaN -313.38  \n",
       "            2025-01-02 10:00:00                  182.890000   45.60  \n",
       "            2025-01-05 05:00:00                   80.750000  -38.64  \n",
       "            2025-01-06 07:00:00                  103.940000   62.61  \n",
       "...                                                     ...     ...  \n",
       "C050        2025-02-26 06:30:00                  304.080000 -162.07  \n",
       "            2025-03-01 07:30:00                  285.203333 -115.44  \n",
       "            2025-03-01 22:00:00                  305.613333  338.74  \n",
       "            2025-03-02 20:00:00                  298.633333 -244.24  \n",
       "            2025-03-03 13:30:00                  292.633333 -112.50  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>3_purchase_rolling_average</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C001</th>\n",
       "      <th>2025-01-01 05:30:00</th>\n",
       "      <td>376.61</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 02:00:00</th>\n",
       "      <td>63.23</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-313.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 10:00:00</th>\n",
       "      <td>108.83</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>182.890000</td>\n",
       "      <td>45.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05 05:00:00</th>\n",
       "      <td>70.19</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>-38.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:00:00</th>\n",
       "      <td>132.80</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>103.940000</td>\n",
       "      <td>62.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>269.66</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>304.080000</td>\n",
       "      <td>-162.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 07:30:00</th>\n",
       "      <td>154.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>285.203333</td>\n",
       "      <td>-115.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>492.96</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>305.613333</td>\n",
       "      <td>338.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>248.72</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>298.633333</td>\n",
       "      <td>-244.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 13:30:00</th>\n",
       "      <td>136.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>292.633333</td>\n",
       "      <td>-112.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:43.975399Z",
     "start_time": "2025-11-17T15:27:43.957242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"5.1\")\n",
    "dfberlin = dfmerged[dfmerged['City'] == 'Berlin'].copy()#selects data only for Berlin\n",
    "\n",
    "dfberlin['3_purchase_rolling_average'] = dfberlin.groupby('Customer_id')['Price'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "dfberlin['diff'] = dfberlin['Price'] - dfberlin['Price'].shift(1)\n",
    "dfberlin"
   ],
   "id": "c20d729cf3f783a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date    City     Month  \\\n",
       "Customer_id Timestamp                                                   \n",
       "C013        2025-01-05 02:30:00  474.31  1995-06-12  Berlin   January   \n",
       "            2025-01-06 00:00:00  410.01  1995-06-12  Berlin   January   \n",
       "            2025-01-07 23:00:00  396.90  1995-06-12  Berlin   January   \n",
       "            2025-01-08 22:00:00   92.70  1995-06-12  Berlin   January   \n",
       "            2025-01-09 04:00:00  392.28  1995-06-12  Berlin   January   \n",
       "...                                 ...         ...     ...       ...   \n",
       "C050        2025-02-26 06:30:00  269.66  1987-08-04  Berlin  February   \n",
       "            2025-03-01 07:30:00  154.22  1987-08-04  Berlin     March   \n",
       "            2025-03-01 22:00:00  492.96  1987-08-04  Berlin     March   \n",
       "            2025-03-02 20:00:00  248.72  1987-08-04  Berlin     March   \n",
       "            2025-03-03 13:30:00  136.22  1987-08-04  Berlin     March   \n",
       "\n",
       "                                 3_purchase_rolling_average    diff  \n",
       "Customer_id Timestamp                                                \n",
       "C013        2025-01-05 02:30:00                         NaN     NaN  \n",
       "            2025-01-06 00:00:00                         NaN  -64.30  \n",
       "            2025-01-07 23:00:00                  427.073333  -13.11  \n",
       "            2025-01-08 22:00:00                  299.870000 -304.20  \n",
       "            2025-01-09 04:00:00                  293.960000  299.58  \n",
       "...                                                     ...     ...  \n",
       "C050        2025-02-26 06:30:00                  304.080000 -162.07  \n",
       "            2025-03-01 07:30:00                  285.203333 -115.44  \n",
       "            2025-03-01 22:00:00                  305.613333  338.74  \n",
       "            2025-03-02 20:00:00                  298.633333 -244.24  \n",
       "            2025-03-03 13:30:00                  292.633333 -112.50  \n",
       "\n",
       "[777 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>3_purchase_rolling_average</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C013</th>\n",
       "      <th>2025-01-05 02:30:00</th>\n",
       "      <td>474.31</td>\n",
       "      <td>1995-06-12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 00:00:00</th>\n",
       "      <td>410.01</td>\n",
       "      <td>1995-06-12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-64.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07 23:00:00</th>\n",
       "      <td>396.90</td>\n",
       "      <td>1995-06-12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>427.073333</td>\n",
       "      <td>-13.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-08 22:00:00</th>\n",
       "      <td>92.70</td>\n",
       "      <td>1995-06-12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>299.870000</td>\n",
       "      <td>-304.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-09 04:00:00</th>\n",
       "      <td>392.28</td>\n",
       "      <td>1995-06-12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>293.960000</td>\n",
       "      <td>299.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>269.66</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>304.080000</td>\n",
       "      <td>-162.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 07:30:00</th>\n",
       "      <td>154.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>285.203333</td>\n",
       "      <td>-115.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>492.96</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>305.613333</td>\n",
       "      <td>338.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>248.72</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>298.633333</td>\n",
       "      <td>-244.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 13:30:00</th>\n",
       "      <td>136.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>292.633333</td>\n",
       "      <td>-112.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:44.003850Z",
     "start_time": "2025-11-17T15:27:43.987545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"5.2\")\n",
    "dfprice = dfmerged[dfmerged['Price'] >1.2*dfmerged['Price'].shift(-1)].copy()\n",
    "\n",
    "dfprice['3_purchase_rolling_average'] = dfprice.groupby('Customer_id')['Price'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "dfprice['diff'] = dfprice['Price'] - dfprice['Price'].shift(1)\n",
    "dfprice"
   ],
   "id": "82174b543a13452d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date       City     Month  \\\n",
       "Customer_id Timestamp                                                      \n",
       "C001        2025-01-01 05:30:00  376.61  1998-12-03  Frankfurt   January   \n",
       "            2025-01-02 10:00:00  108.83  1998-12-03  Frankfurt   January   \n",
       "            2025-01-06 11:30:00  415.65  1998-12-03  Frankfurt   January   \n",
       "            2025-01-07 19:30:00  382.14  1998-12-03  Frankfurt   January   \n",
       "            2025-01-10 10:30:00  265.98  1998-12-03  Frankfurt   January   \n",
       "...                                 ...         ...        ...       ...   \n",
       "C050        2025-02-22 10:30:00   80.18  1987-08-04     Berlin  February   \n",
       "            2025-02-25 08:00:00  431.73  1987-08-04     Berlin  February   \n",
       "            2025-02-26 06:30:00  269.66  1987-08-04     Berlin  February   \n",
       "            2025-03-01 22:00:00  492.96  1987-08-04     Berlin     March   \n",
       "            2025-03-02 20:00:00  248.72  1987-08-04     Berlin     March   \n",
       "\n",
       "                                 3_purchase_rolling_average    diff  \n",
       "Customer_id Timestamp                                                \n",
       "C001        2025-01-01 05:30:00                         NaN     NaN  \n",
       "            2025-01-02 10:00:00                         NaN -267.78  \n",
       "            2025-01-06 11:30:00                  300.363333  306.82  \n",
       "            2025-01-07 19:30:00                  302.206667  -33.51  \n",
       "            2025-01-10 10:30:00                  354.590000 -116.16  \n",
       "...                                                     ...     ...  \n",
       "C050        2025-02-22 10:30:00                  290.500000 -316.21  \n",
       "            2025-02-25 08:00:00                  302.766667  351.55  \n",
       "            2025-02-26 06:30:00                  260.523333 -162.07  \n",
       "            2025-03-01 22:00:00                  398.116667  223.30  \n",
       "            2025-03-02 20:00:00                  337.113333 -244.24  \n",
       "\n",
       "[1261 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>3_purchase_rolling_average</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C001</th>\n",
       "      <th>2025-01-01 05:30:00</th>\n",
       "      <td>376.61</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 10:00:00</th>\n",
       "      <td>108.83</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-267.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 11:30:00</th>\n",
       "      <td>415.65</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>300.363333</td>\n",
       "      <td>306.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07 19:30:00</th>\n",
       "      <td>382.14</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>302.206667</td>\n",
       "      <td>-33.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-10 10:30:00</th>\n",
       "      <td>265.98</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>354.590000</td>\n",
       "      <td>-116.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-22 10:30:00</th>\n",
       "      <td>80.18</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>290.500000</td>\n",
       "      <td>-316.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-25 08:00:00</th>\n",
       "      <td>431.73</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>302.766667</td>\n",
       "      <td>351.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>269.66</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>260.523333</td>\n",
       "      <td>-162.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>492.96</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>398.116667</td>\n",
       "      <td>223.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>248.72</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>337.113333</td>\n",
       "      <td>-244.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1261 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:44.043733Z",
     "start_time": "2025-11-17T15:27:44.025893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"6.1\")\n",
    "above18=dfmerged.groupby('Customer_id').filter(lambda g: g['Price'].sum() > 18000) #makes groups by customer id and selects only those whoose expences are greater then 18 000\n",
    "above18"
   ],
   "id": "765b607fe404eeb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date    City    Month  \\\n",
       "Customer_id Timestamp                                                  \n",
       "C026        2025-01-01 07:30:00  175.11  1971-09-03  Berlin  January   \n",
       "            2025-01-01 20:00:00  449.11  1971-09-03  Berlin  January   \n",
       "            2025-01-02 08:00:00  345.00  1971-09-03  Berlin  January   \n",
       "            2025-01-04 19:00:00  370.10  1971-09-03  Berlin  January   \n",
       "            2025-01-05 00:00:00  234.89  1971-09-03  Berlin  January   \n",
       "...                                 ...         ...     ...      ...   \n",
       "C049        2025-03-01 09:30:00   61.88  1979-01-20  Munich    March   \n",
       "            2025-03-01 17:00:00  415.55  1979-01-20  Munich    March   \n",
       "            2025-03-03 10:00:00  261.45  1979-01-20  Munich    March   \n",
       "            2025-03-03 20:30:00  449.69  1979-01-20  Munich    March   \n",
       "            2025-03-04 10:30:00  419.03  1979-01-20  Munich    March   \n",
       "\n",
       "                                 3_purchase_rolling_average    diff  \n",
       "Customer_id Timestamp                                                \n",
       "C026        2025-01-01 07:30:00                         NaN -243.97  \n",
       "            2025-01-01 20:00:00                         NaN  274.00  \n",
       "            2025-01-02 08:00:00                  323.073333 -104.11  \n",
       "            2025-01-04 19:00:00                  388.070000   25.10  \n",
       "            2025-01-05 00:00:00                  316.663333 -135.21  \n",
       "...                                                     ...     ...  \n",
       "C049        2025-03-01 09:30:00                  232.853333 -365.68  \n",
       "            2025-03-01 17:00:00                  301.663333  353.67  \n",
       "            2025-03-03 10:00:00                  246.293333 -154.10  \n",
       "            2025-03-03 20:30:00                  375.563333  188.24  \n",
       "            2025-03-04 10:30:00                  376.723333  -30.66  \n",
       "\n",
       "[286 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>3_purchase_rolling_average</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C026</th>\n",
       "      <th>2025-01-01 07:30:00</th>\n",
       "      <td>175.11</td>\n",
       "      <td>1971-09-03</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-243.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 20:00:00</th>\n",
       "      <td>449.11</td>\n",
       "      <td>1971-09-03</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 08:00:00</th>\n",
       "      <td>345.00</td>\n",
       "      <td>1971-09-03</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>323.073333</td>\n",
       "      <td>-104.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-04 19:00:00</th>\n",
       "      <td>370.10</td>\n",
       "      <td>1971-09-03</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>388.070000</td>\n",
       "      <td>25.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05 00:00:00</th>\n",
       "      <td>234.89</td>\n",
       "      <td>1971-09-03</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>January</td>\n",
       "      <td>316.663333</td>\n",
       "      <td>-135.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C049</th>\n",
       "      <th>2025-03-01 09:30:00</th>\n",
       "      <td>61.88</td>\n",
       "      <td>1979-01-20</td>\n",
       "      <td>Munich</td>\n",
       "      <td>March</td>\n",
       "      <td>232.853333</td>\n",
       "      <td>-365.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 17:00:00</th>\n",
       "      <td>415.55</td>\n",
       "      <td>1979-01-20</td>\n",
       "      <td>Munich</td>\n",
       "      <td>March</td>\n",
       "      <td>301.663333</td>\n",
       "      <td>353.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 10:00:00</th>\n",
       "      <td>261.45</td>\n",
       "      <td>1979-01-20</td>\n",
       "      <td>Munich</td>\n",
       "      <td>March</td>\n",
       "      <td>246.293333</td>\n",
       "      <td>-154.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 20:30:00</th>\n",
       "      <td>449.69</td>\n",
       "      <td>1979-01-20</td>\n",
       "      <td>Munich</td>\n",
       "      <td>March</td>\n",
       "      <td>375.563333</td>\n",
       "      <td>188.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-04 10:30:00</th>\n",
       "      <td>419.03</td>\n",
       "      <td>1979-01-20</td>\n",
       "      <td>Munich</td>\n",
       "      <td>March</td>\n",
       "      <td>376.723333</td>\n",
       "      <td>-30.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:44.075348Z",
     "start_time": "2025-11-17T15:27:44.050541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"6.2\")\n",
    "dfmerged['average_diff']=dfmerged.groupby('Customer_id')['Price'].transform(lambda x: (x - x.shift(1)).mean()) #makes groups by customer id and calculates the average of differences for each customer\n",
    "dfmerged"
   ],
   "id": "79ae7ea33b831171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  Price   Born_date       City     Month  \\\n",
       "Customer_id Timestamp                                                      \n",
       "C001        2025-01-01 05:30:00  376.61  1998-12-03  Frankfurt   January   \n",
       "            2025-01-02 02:00:00   63.23  1998-12-03  Frankfurt   January   \n",
       "            2025-01-02 10:00:00  108.83  1998-12-03  Frankfurt   January   \n",
       "            2025-01-05 05:00:00   70.19  1998-12-03  Frankfurt   January   \n",
       "            2025-01-06 07:00:00  132.80  1998-12-03  Frankfurt   January   \n",
       "...                                 ...         ...        ...       ...   \n",
       "C050        2025-02-26 06:30:00  269.66  1987-08-04     Berlin  February   \n",
       "            2025-03-01 07:30:00  154.22  1987-08-04     Berlin     March   \n",
       "            2025-03-01 22:00:00  492.96  1987-08-04     Berlin     March   \n",
       "            2025-03-02 20:00:00  248.72  1987-08-04     Berlin     March   \n",
       "            2025-03-03 13:30:00  136.22  1987-08-04     Berlin     March   \n",
       "\n",
       "                                 3_purchase_rolling_average    diff  \\\n",
       "Customer_id Timestamp                                                 \n",
       "C001        2025-01-01 05:30:00                         NaN     NaN   \n",
       "            2025-01-02 02:00:00                         NaN -313.38   \n",
       "            2025-01-02 10:00:00                  182.890000   45.60   \n",
       "            2025-01-05 05:00:00                   80.750000  -38.64   \n",
       "            2025-01-06 07:00:00                  103.940000   62.61   \n",
       "...                                                     ...     ...   \n",
       "C050        2025-02-26 06:30:00                  304.080000 -162.07   \n",
       "            2025-03-01 07:30:00                  285.203333 -115.44   \n",
       "            2025-03-01 22:00:00                  305.613333  338.74   \n",
       "            2025-03-02 20:00:00                  298.633333 -244.24   \n",
       "            2025-03-03 13:30:00                  292.633333 -112.50   \n",
       "\n",
       "                                 average_diff  \n",
       "Customer_id Timestamp                          \n",
       "C001        2025-01-01 05:30:00     -2.371636  \n",
       "            2025-01-02 02:00:00     -2.371636  \n",
       "            2025-01-02 10:00:00     -2.371636  \n",
       "            2025-01-05 05:00:00     -2.371636  \n",
       "            2025-01-06 07:00:00     -2.371636  \n",
       "...                                       ...  \n",
       "C050        2025-02-26 06:30:00     -1.879828  \n",
       "            2025-03-01 07:30:00     -1.879828  \n",
       "            2025-03-01 22:00:00     -1.879828  \n",
       "            2025-03-02 20:00:00     -1.879828  \n",
       "            2025-03-03 13:30:00     -1.879828  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Born_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>3_purchase_rolling_average</th>\n",
       "      <th>diff</th>\n",
       "      <th>average_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C001</th>\n",
       "      <th>2025-01-01 05:30:00</th>\n",
       "      <td>376.61</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 02:00:00</th>\n",
       "      <td>63.23</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-313.38</td>\n",
       "      <td>-2.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 10:00:00</th>\n",
       "      <td>108.83</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>182.890000</td>\n",
       "      <td>45.60</td>\n",
       "      <td>-2.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05 05:00:00</th>\n",
       "      <td>70.19</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>-38.64</td>\n",
       "      <td>-2.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:00:00</th>\n",
       "      <td>132.80</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>January</td>\n",
       "      <td>103.940000</td>\n",
       "      <td>62.61</td>\n",
       "      <td>-2.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>269.66</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>February</td>\n",
       "      <td>304.080000</td>\n",
       "      <td>-162.07</td>\n",
       "      <td>-1.879828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 07:30:00</th>\n",
       "      <td>154.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>285.203333</td>\n",
       "      <td>-115.44</td>\n",
       "      <td>-1.879828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>492.96</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>305.613333</td>\n",
       "      <td>338.74</td>\n",
       "      <td>-1.879828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>248.72</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>298.633333</td>\n",
       "      <td>-244.24</td>\n",
       "      <td>-1.879828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 13:30:00</th>\n",
       "      <td>136.22</td>\n",
       "      <td>1987-08-04</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>March</td>\n",
       "      <td>292.633333</td>\n",
       "      <td>-112.50</td>\n",
       "      <td>-1.879828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:44.098033Z",
     "start_time": "2025-11-17T15:27:44.083335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"7.1\")\n",
    "monthlyrev=dfmerged.groupby(['Customer_id','Month']).agg(sum =('Price', 'sum')) #same as we did with month and city\n",
    "monthlyrev['growth']=monthlyrev['sum']-monthlyrev['sum'].shift(1) #calculates the difference of monthly revenue and previous monthly revenue for each customer\n",
    "monthlyrev"
   ],
   "id": "eb04a588ad58a86a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                           sum   growth\n",
       "Customer_id Month                      \n",
       "C001        February   5204.79      NaN\n",
       "            January    7302.10  2097.31\n",
       "            March       548.86 -6753.24\n",
       "C002        February   7838.50  7289.64\n",
       "            January    7538.37  -300.13\n",
       "...                        ...      ...\n",
       "C049        January   10952.12  5391.10\n",
       "            March      1607.60 -9344.52\n",
       "C050        February   6232.23  4624.63\n",
       "            January    5379.40  -852.83\n",
       "            March      1032.12 -4347.28\n",
       "\n",
       "[149 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>growth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">C001</th>\n",
       "      <th>February</th>\n",
       "      <td>5204.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>7302.10</td>\n",
       "      <td>2097.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>548.86</td>\n",
       "      <td>-6753.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C002</th>\n",
       "      <th>February</th>\n",
       "      <td>7838.50</td>\n",
       "      <td>7289.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>7538.37</td>\n",
       "      <td>-300.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C049</th>\n",
       "      <th>January</th>\n",
       "      <td>10952.12</td>\n",
       "      <td>5391.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>1607.60</td>\n",
       "      <td>-9344.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">C050</th>\n",
       "      <th>February</th>\n",
       "      <td>6232.23</td>\n",
       "      <td>4624.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>5379.40</td>\n",
       "      <td>-852.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>1032.12</td>\n",
       "      <td>-4347.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:27:44.133697Z",
     "start_time": "2025-11-17T15:27:44.119090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"7.2\")\n",
    "dfmerged.groupby('Customer_id').agg(cumsum =('Price', 'cumsum'))#calculates the cumulative sum for each custumer"
   ],
   "id": "42385a962de7df30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                   cumsum\n",
       "Customer_id Timestamp                    \n",
       "C001        2025-01-01 05:30:00    376.61\n",
       "            2025-01-02 02:00:00    439.84\n",
       "            2025-01-02 10:00:00    548.67\n",
       "            2025-01-05 05:00:00    618.86\n",
       "            2025-01-06 07:00:00    751.66\n",
       "...                                   ...\n",
       "C050        2025-02-26 06:30:00  11611.63\n",
       "            2025-03-01 07:30:00  11765.85\n",
       "            2025-03-01 22:00:00  12258.81\n",
       "            2025-03-02 20:00:00  12507.53\n",
       "            2025-03-03 13:30:00  12643.75\n",
       "\n",
       "[3000 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cumsum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C001</th>\n",
       "      <th>2025-01-01 05:30:00</th>\n",
       "      <td>376.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 02:00:00</th>\n",
       "      <td>439.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 10:00:00</th>\n",
       "      <td>548.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05 05:00:00</th>\n",
       "      <td>618.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:00:00</th>\n",
       "      <td>751.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C050</th>\n",
       "      <th>2025-02-26 06:30:00</th>\n",
       "      <td>11611.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 07:30:00</th>\n",
       "      <td>11765.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 22:00:00</th>\n",
       "      <td>12258.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-02 20:00:00</th>\n",
       "      <td>12507.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03 13:30:00</th>\n",
       "      <td>12643.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
